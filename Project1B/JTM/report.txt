The selected recipe for this task is as follows:
1) Splitting the training set into k=10 subsets
2) For each validation-training suplit: 
       Ridge regression is run with a number of regularization strengths.
3)     Regularization with the best performance on the validation set is chosen.
4)     A model is trained with Ridge + chosen regularization, using entire training set
5) Models generated by different choices of regularization on different validation sets are averaged
6) Repeat 1-5 several times (n=5), and average the obtained models

Ridge regression is used as the normal equation is highly ill-conditioned (closed form Hessian has a condition number of 4e+11). Regularization is required to eliminate the near-degeneracy of the training set.
We decide to substitute model averaging or ensembling for original cross-validation due to 3 reasons: 
1) Checking the scores (evaluated with average RMSEs) of different regularization parameters, we note that the score is very similar in a reasonably wide range (lambda=1e0~1e+2), and it is not convincing to choose one over the other; the learnt model is also stable with different parameters, thus "averagable";
2) Checking the scores on different validation sets, we note that the best-performing regularization varies significantly from one to the other;
3) Also the submission scores from model averaging is slightly better than cross-validation.
Based on these reasons, I believe it might be benefitial to use model averaging instead of one single learnt model, in order to mitigate a specific choice of regularization strength.
