# -*- coding: utf-8 -*-
"""FoodSim.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eQdYR6uS9eP5H8blY5kfJ6nOGAh3nGhJ

# Similarity of Food Pictures

Use a Siamese network with a triplet margin loss to identify food pictures with similar Â´tastes' in the triplets.

**Optional block**: mounting info from google drive to current session.

This significantly speeds up the data loading follows. **Strongly recommended!**

**REMEMBER to SYNC THE TASK3 OUTPUTS IN GOOGLE DRIVE at the end of the day !!!** Otherwise the trained models, tens of minutes of training will be lost for good.
"""

!cp -r /content/drive/MyDrive/Colab\ Notebooks/task3 /content/.

!rm -r /content/drive/MyDrive/Colab\ Notebooks/task3/task3

!rsync -av --info=progress2 /content/task3/outputs/ /content/drive/MyDrive/Colab\ Notebooks/task3/outputs/.

from google.colab import drive
drive.flush_and_unmount()

# Initial importing

import numpy as np
import random
import os, glob

import torch
from torch import nn, optim
from torch.utils.data import Dataset, DataLoader
import torchvision as tvision
from torchvision import datasets, transforms

import matplotlib.pyplot as plt

PROJ_DIR = '/content/task3'
PIC_DIR = os.path.join(PROJ_DIR, 'food')
PIC_SIZE = 128

# Transforms
trans_resize = transforms.Compose([
    transforms.Resize(size=(PIC_SIZE, PIC_SIZE)),
])

# Display a random picture
pic_name = random.choice(os.listdir(PIC_DIR))
pic = tvision.io.read_image(os.path.join(PIC_DIR, pic_name))
pic = trans_resize(pic)
plt.imshow(np.transpose(pic, [1, 2, 0]))
plt.title(pic_name)
plt.show()

"""## Build a dataset based on triplets and food pictures

### Optional: check mean and stdev

For normalization purposes it does not seem really necessary? In practice the linear maps simply from [0, 1] or [0, 255] to [-1, 1] seem to suffice.
"""

# Check statistics of the pictures

# Statistics for all channels combined:
# STDEV = 67.0, MEAN = 130.6

std_mean_array = np.zeros((len(os.listdir(PIC_DIR)), 2))
for i, fname in enumerate(os.listdir(PIC_DIR)[-10:]):
    if fname[0] == '.':
        continue
    pic = trans_resize(tvision.io.read_image(os.path.join(PIC_DIR, fname)))
    std_mean_array[-11+i, :] = tuple(map(float, torch.std_mean(pic.to(torch.float))))
    if (i+1) % 500 == 0:
        print(f"{i+1}/10011")
np.mean(std_mean_array[:-1, :], axis=0)

"""### Triplet dataset and utilities"""

from torchvision.transforms.transforms import ToTensor
LINE_STRIDE = 18
# MULTI_MEAN = 130.6
# MULTI_STDEV = 67.0
MULTI_MEAN = 127.5
MULTI_STDEV = 127.5

trans_train = transforms.Compose([
    transforms.Resize(size=(PIC_SIZE, PIC_SIZE)),
    transforms.Normalize((MULTI_MEAN, MULTI_MEAN, MULTI_MEAN), 
                         (MULTI_STDEV, MULTI_STDEV, MULTI_STDEV))
])

def read_triplet(fname, line_idx):
    with open(os.path.join(PROJ_DIR, fname), 'r') as fread:
        fread.seek(line_idx*LINE_STRIDE)
        triplet = fread.readline().strip().split(' ')
    return triplet

def get_triplet_img(fdir, triplet):
    imgs = [trans_train(tvision.io.read_image(os.path.join(fdir, f'{fname}.jpg')).to(torch.float)) \
            for fname in triplet]
    return imgs

def imshow(img):
    img = img*MULTI_STDEV + MULTI_MEAN
    plt.imshow(np.transpose(img.to(torch.uint8), [1, 2, 0]))


class TripletDataset(Dataset):

    def __init__(self, image_folder, triplet_text, transform=None) -> None:
        super().__init__()
        self.image_folder = image_folder
        self.triplet_text = triplet_text
        self.transform = transform
        self.lines = self.count_lines()
    
    def __len__(self):
        return self.lines
    
    def __getitem__(self, index):
        triplet_idx = read_triplet(self.triplet_text, index)
        imgs = get_triplet_img(self.image_folder, triplet_idx)
        return imgs[0], imgs[1], imgs[2]
    
    def count_lines(self):
        with open(os.path.join(PROJ_DIR, self.triplet_text), 'r') as fread:
            n_lines = sum([1 for line in fread])
        return n_lines


triplet_train_ds = TripletDataset(PIC_DIR, 'train_triplets.txt', transform=trans_train)

# Display a set of triplet images

plt.figure(figsize=(12, 4))
imgs = get_triplet_img(PIC_DIR, read_triplet('train_triplets.txt', 0))
imshow(tvision.utils.make_grid(imgs))
# imgs[0].max(), imgs[0].min()
plt.show()

"""### Data loader"""

BATCH_SIZE = 32

triplet_loader_train = DataLoader(triplet_train_ds, shuffle=False, batch_size=BATCH_SIZE, num_workers=2)

batch_instance = next(iter(triplet_loader_train))
batch_instance = torch.cat(batch_instance, dim=0)
batch_instance.size()

plt.figure(figsize=(24, 9))
imshow(tvision.utils.make_grid(batch_instance, nrow=BATCH_SIZE))
plt.show()
# batch_instance[0]

"""## Build & Train Triplet Network"""

class TripletNetwork(nn.Module):

    def __init__(self) -> None:
        super().__init__()

        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)
        self.pool1 = nn.MaxPool2d(4)
        self.conv2 = nn.Conv2d(6, 16, kernel_size=4)
        self.pool2 = nn.MaxPool2d(2)
        self.conv3 = nn.Conv2d(16, 16, kernel_size=3)
        self.pool3 = nn.MaxPool2d(2)
        
        # input siye = 144 * ((((n - (5-1))/2 - (3-1))/2 - (3-1))/2)^2
        self.fc1 = nn.Linear(self.num_linear_inputs(), 128)
        self.fc2 = nn.Linear(128, 8)
        # self.fc3 = nn.Linear(128, 8)

        # activation
        self.actf = nn.ReLU()
    
    def num_linear_inputs(self):
        size = (PIC_SIZE - (self.conv1.kernel_size[0] - 1))/self.pool1.kernel_size
        size = (size - (self.conv2.kernel_size[0] - 1))/self.pool2.kernel_size
        size = (size - (self.conv3.kernel_size[0] - 1))/self.pool3.kernel_size
        size = self.conv3.out_channels*(size**2)
        return int(size)

    def forward_once(self, x):
        output = self.pool1(self.actf(self.conv1(x)))
        output = self.pool2(self.actf(self.conv2(output)))
        output = self.pool3(self.actf(self.conv3(output)))
        output = torch.flatten(output, start_dim=1)
        output = self.actf(self.fc1(output))
        # output = self.actf(self.fc2(output))
        output = self.fc2(output)
        return output
    
    def forward(self, x_anchor, x_pos, x_neg):

        o_anchor = self.forward_once(x_anchor)
        o_pos = self.forward_once(x_pos)
        o_neg = self.forward_once(x_neg)

        return o_anchor, o_pos, o_neg


triplet_net = TripletNetwork()
triplet_net

device = 'cuda' if torch.cuda.is_available() else 'cpu'
triplet_net = triplet_net.to(device)

criterion = nn.TripletMarginLoss(margin=0.5)
optimizer = optim.Adam(triplet_net.parameters(), lr=1e-3, weight_decay=5e-4)

epochs = 4
print_every = 100
validations = []
OUT_DIR = os.path.join(PROJ_DIR, 'outputs')

for epoch in range(epochs):

    running_loss = 0.0
    validation_loss = 0.0
    count_correct = 0
    count_total = 0

    for i, data in enumerate(triplet_loader_train):

        if i <= len(triplet_train_ds) // BATCH_SIZE - 100:

            i_ach = data[0].to(device)
            i_pos = data[1].to(device)
            i_neg = data[2].to(device)

            optimizer.zero_grad()

            o_ach, o_pos, o_neg = triplet_net(i_ach, i_pos, i_neg)
            loss = criterion(o_ach, o_pos, o_neg)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

            if (i+1) % print_every == 0:
                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / print_every:.3f}')
                running_loss = 0.0
        
        else:
    
            with torch.no_grad():
                i_ach = data[0].to(device)
                i_pos = data[1].to(device)
                i_neg = data[2].to(device)

                o_ach, o_pos, o_neg = triplet_net(i_ach, i_pos, i_neg)
                loss = criterion(o_ach, o_pos, o_neg)
                d_pos = torch.sum((o_ach - o_pos)**2, dim=1)
                d_neg = torch.sum((o_ach - o_neg)**2, dim=1)
                count_correct += (d_neg > d_pos).sum().item()
                count_total += d_pos.size()[0]

                validation_loss += loss.item()
        
    if len(validations) > 0 and validation_loss < validations[-1]:
        torch.save(triplet_net.state_dict(), os.path.join(OUT_DIR, f'temp_ep{epoch}.pth'))
    validations.append(validation_loss)
    
    print(f'Epoch {epoch + 1} validation loss: {validation_loss/100:.3f}, accuracy: {count_correct/count_total:.3f}')

len(triplet_train_ds)

"""## Build & Train on Pretrained Convolutional Layers"""

model_refit = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)
for name, param in model_refit.named_parameters():
    print(name)
    param.requires_grad = False

"""Precalculate the pretrained convolutional layer output for pictures"""

for i, fname in enumerate(os.listdir(PIC_DIR)):
    if fname[-3:] != 'jpg':
        continue
    img = tvision.io.read_image(os.path.join(PIC_DIR, fname))
    if img.size(1) <= 224 or img.size(2) <= 224:
        print(fname)
    if (i+1) % 1000 == 0:
        print(i+1)

model_refit.fc = nn.Identity()
trans_resnet = transforms.Compose([
    transforms.Resize()
])

with torch.no_grad():
    for i, fname in enumerate(os.listdir(PIC_DIR)):
        if fname[-3:] == 'jpg':
            img = trans_train(tvision.io.read_image(os.path.join(PIC_DIR, fname)).to(torch.float))
            resnet_output = torch.squeeze(model_refit.forward(torch.unsqueeze(img, 0)))
            torch.save(resnet_output, os.path.join(PROJ_DIR, 'food_resnet18', fname[:-4] + '.pt'))
        if (i + 1) % 1000 == 0:
            print(f'{i+1} images saved with resnet-18 output.')

"""Dataset and dataloader for RESNET-18 outputs"""

class TripletVectorDataset(Dataset):

    def __init__(self, vector_folder, triplet_text, transform=None) -> None:
        super().__init__()
        self.vector_folder = vector_folder
        self.triplet_text = triplet_text
        self.transform = transform
        self.lines = self.count_lines()
    
    def __len__(self):
        return self.lines
    
    def __getitem__(self, index):
        triplet_idx = read_triplet(self.triplet_text, index)
        vectors = [torch.load(os.path.join(self.vector_folder, f'{idx}.pt')) \
                for idx in triplet_idx]
        return vectors[0], vectors[1], vectors[2]
    
    def count_lines(self):
        with open(os.path.join(PROJ_DIR, self.triplet_text), 'r') as fread:
            n_lines = sum([1 for line in fread])
        return n_lines

"""Modify the model so that the last few (oft. fully connected) layers can be trained"""

# For loading the complete model
# not necessary if the convolutional layer outputs have been precomputed
model_refit.fc = nn.Linear(model_refit.fc.in_features, 32)

# Building a new model with only fc layers
class FCNetwork(nn.Module):

    def __init__(self) -> None:
        super().__init__()
        self.fc1 = nn.Linear(512, 128)
        self.fc2 = nn.Linear(128, 32)
        self.acf = nn.ReLU()
    
    def forward(self, x):
        z = self.acf(self.fc1(x))
        z = self.fc2(z)
        return z

"""Wrapper class that turns any single neural network into a triplet neural network"""

class TripletWrapper(nn.Module):

    def __init__(self, single_model) -> None:
        super().__init__()
        self.single_model = single_model
    
    def forward(self, x_anchor, x_pos, x_neg):
        o_anchor = self.single_model(x_anchor)
        o_pos = self.single_model(x_pos)
        o_neg = self.single_model(x_neg)
        return o_anchor, o_pos, o_neg

ds_resnet18_train = TripletVectorDataset(os.path.join(PROJ_DIR, 'food_resnet18'), 'train_triplets_split1.txt')
loader_resnet18_train = DataLoader(ds_resnet18_train, shuffle=False, batch_size=BATCH_SIZE, num_workers=0)

net_train = FCNetwork()
triplet_refit = TripletWrapper(net_train)

device = 'cuda' if torch.cuda.is_available() else 'cpu'
net_train = net_train.to(device)

criterion = nn.TripletMarginLoss(margin=0.5)
optimizer = optim.Adam(net_train.parameters(), lr=1e-3, weight_decay=1e-4)

epochs = 4
print_every = 100

for epoch in range(epochs):

    running_loss = 0.0
    validation_loss = 0.0
    count_correct = 0
    count_total = 0

    for i, data in enumerate(loader_resnet18_train):

        i_ach = data[0].to(device)
        i_pos = data[1].to(device)
        i_neg = data[2].to(device)

        optimizer.zero_grad()

        o_ach, o_pos, o_neg = triplet_refit(i_ach, i_pos, i_neg)
        loss = criterion(o_ach, o_pos, o_neg)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

        if (i+1) % print_every == 0:
            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / print_every:.3f}')
            running_loss = 0.0

    #     if i <= len(ds_resnet18_train) // BATCH_SIZE - 100:

    #         i_ach = data[0].to(device)
    #         i_pos = data[1].to(device)
    #         i_neg = data[2].to(device)

    #         optimizer.zero_grad()

    #         o_ach, o_pos, o_neg = triplet_refit(i_ach, i_pos, i_neg)
    #         loss = criterion(o_ach, o_pos, o_neg)
    #         loss.backward()
    #         optimizer.step()

    #         running_loss += loss.item()

    #         if (i+1) % print_every == 0:
    #             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / print_every:.3f}')
    #             running_loss = 0.0
        
    #     else:
    
    #         with torch.no_grad():
    #             i_ach = data[0].to(device)
    #             i_pos = data[1].to(device)
    #             i_neg = data[2].to(device)

    #             o_ach, o_pos, o_neg = triplet_refit(i_ach, i_pos, i_neg)
    #             loss = criterion(o_ach, o_pos, o_neg)
    #             d_pos = torch.sum((o_ach - o_pos)**2, dim=1)
    #             d_neg = torch.sum((o_ach - o_neg)**2, dim=1)
    #             count_correct += (d_neg > d_pos).sum().item()
    #             count_total += d_pos.size()[0]

    #             validation_loss += loss.item()
        
    # print(f'Epoch {epoch + 1} validation loss: {validation_loss / 100:.3f}, accuracy: {count_correct / count_total:.3f}')

with open(os.path.join(PROJ_DIR, 'train_triplets.txt'), 'r') as fr:
    nrow = 0
    with open(os.path.join(PROJ_DIR, 'train_triplets_split1.txt'), 'w') as fw:
        for line in fr:
            fw.write(line)
            nrow += 1
            if nrow == 56320:
                break
    with open(os.path.join(PROJ_DIR, 'train_triplets_split2.txt'), 'w') as fw:
        for line in fr:
            fw.write(line)
            nrow += 1

"""## Evaluation and Outputs
Evaluate the results on:
- Training set
- Test set (predict/recall)
"""

OUT_DIR = os.path.join(PROJ_DIR, 'outputs')

# Select a network
# net = triplet_refit
net = triplet_net
# net.load_state_dict(torch.load(os.path.join(OUT_DIR, 'net_triplet-full-c2f2e2.pth')))

# Select a network label
# This label will be used to save the network and its predictions
net_label = 'c3f2e4'

# Save the trained model
torch.save(net.state_dict(), os.path.join(OUT_DIR, f'net_{net_label}.pth'))

net

# Training set recall

fname_train_recall = 'train_recall_' + net_label + '.txt'

# Used on input from images
with open(os.path.join(OUT_DIR, fname_train_recall), 'w') as fwrite:
    with torch.no_grad():
        for i, data in enumerate(triplet_loader_train):
            i_ach, i_pos, i_neg = data[0].to(device), data[1].to(device), data[2].to(device)
            o_ach, o_pos, o_neg = net(i_ach, i_pos, i_neg)
            d_pos = torch.sum((o_ach - o_pos)**2, dim=1)
            d_neg = torch.sum((o_ach - o_neg)**2, dim=1)
            print(*tuple(((d_neg > d_pos)*1).tolist()), sep='\n', file=fwrite)
            if (i+1) % 100 == 0:
                print(f'{i + 1:5d} batches recalled.')

# Used when input vectors are precomputed
# with open(os.path.join(OUT_DIR, fname_train_recall), 'w') as fwrite:
#     with torch.no_grad():
#         for i, data in enumerate(loader_resnet18_train):
#             i_ach, i_pos, i_neg = data[0].to(device), data[1].to(device), data[2].to(device)
#             o_ach, o_pos, o_neg = net(i_ach, i_pos, i_neg)
#             d_pos = torch.sum((o_ach - o_pos)**2, dim=1)
#             d_neg = torch.sum((o_ach - o_neg)**2, dim=1)
#             print(*tuple(((d_neg > d_pos)*1).tolist()), sep='\n', file=fwrite)
#             if (i+1) % 100 == 0:
#                 print(f'{i + 1:5d} batches recalled.')

with open(os.path.join(OUT_DIR, fname_train_recall), 'r') as fread:
    predict = [int(line.strip()) for line in fread]
    accuracy = sum(predict)/len(predict)

print(f'Accuracy = {accuracy}')

triplet_test_ds = TripletDataset(PIC_DIR, 'test_triplets.txt', transform=trans_train)
triplet_test_loader = DataLoader(triplet_test_ds, shuffle=False, batch_size=BATCH_SIZE, num_workers=0)

# triplet_test_ds = TripletVectorDataset(os.path.join(PROJ_DIR, 'food_resnet18'), 'train_triplets_split2_permute.txt')
# triplet_loader_test = DataLoader(triplet_test_ds, shuffle=False, batch_size=BATCH_SIZE, num_workers=0)

fname_test_predict = 'test_predict_' + net_label + '.txt'

with open(os.path.join(OUT_DIR, fname_test_predict), 'w') as fwrite:
    with torch.no_grad():
        for i, data in enumerate(triplet_test_loader):
            i_ach, i_pos, i_neg = data[0].to(device), data[1].to(device), data[2].to(device)
            o_ach, o_pos, o_neg = net(i_ach, i_pos, i_neg)
            d_pos = torch.sum((o_ach - o_pos)**2, dim=1)
            d_neg = torch.sum((o_ach - o_neg)**2, dim=1)
            # print(*tuple(list(zip([i]*len(d_neg), ((d_neg > d_pos)*1).tolist()))), sep='\n', file=fwrite)
            print(*tuple(((d_neg > d_pos)*1).tolist()), sep='\n', file=fwrite)
            if (i+1) % 100 == 0:
                print(f'{i + 1:5d} batches predicted')

predict1.size

with open('/content/task3/outputs/test_predict_triplet-full-c2f2e2.txt', 'r') as f1:
    with open('/content/task3/outputs/test_predict_triplet-full_m5e-1.txt', 'r') as f2:
        with open('/content/task3/outputs/test_predict_c3f2e4.txt', 'r') as f3:
            predict1 = np.array([int(line.strip()) for line in f1], dtype=int)
            predict2 = np.array([int(line.strip()) for line in f2], dtype=int)
            predict3 = np.array([int(line.strip()) for line in f3], dtype=int)

sum(predict1 == predict2)/predict1.size, sum(predict2 == predict3)/predict2.size, sum(predict3 == predict1)/predict3.size

triplet_test_ds = TripletVectorDataset(os.path.join(PROJ_DIR, 'food_resnet18'), 'train_triplets.txt')
triplet_loader_test = DataLoader(triplet_test_ds, shuffle=False, batch_size=BATCH_SIZE, num_workers=0)

validation_loss = 0.0
count_correct = 0
count_total = 0

for i, data in enumerate(loader_resnet18_train):

    if i <= len(ds_resnet18_train) // BATCH_SIZE - 100:
        continue        
    else:
        with torch.no_grad():
            i_ach = data[0].to(device)
            i_pos = data[1].to(device)
            i_neg = data[2].to(device)

            o_ach, o_pos, o_neg = triplet_refit(i_ach, i_pos, i_neg)
            loss = criterion(o_ach, o_pos, o_neg)
            d_pos = torch.sum((o_ach - o_pos)**2, dim=1)
            d_neg = torch.sum((o_ach - o_neg)**2, dim=1)
            count_correct += (d_neg > d_pos).sum().item()
            count_total += d_pos.size()[0]

            validation_loss += loss.item()
    
print(f'Validation loss: {validation_loss / 100:.3f}, accuracy: {count_correct / count_total:.3f}')

permute_array = np.random.randint(2, size=100*32)

with open(os.path.join(PROJ_DIR, 'train_triplets_split2.txt'), 'r') as fr:
    with open(os.path.join(PROJ_DIR, 'train_triplets_split2_permute.txt'), 'w') as fw:
        for i, line in enumerate(fr):
            idx = line.strip().split(' ')
            if permute_array[i] == 0:
                fw.write(' '.join([idx[0], idx[2], idx[1]]) + '\n')
            else:
                fw.write(' '.join([idx[0], idx[1], idx[2]]) + '\n')

with open(os.path.join(PROJ_DIR, 'permute.txt'), 'w') as fw:
    print(*tuple(permute_array), sep='\n', file=fw)

tuple(np.array([1, 2, 3]))

